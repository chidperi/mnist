{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import mnist_data\n",
    "import numpy as np\n",
    "import GAN\n",
    "\n",
    "from keras import Input, Model, Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Conv2DTranspose, Reshape, BatchNormalization\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File name: CNN\n",
    "# Copyright 2018 Chidambaram Periakaruppan\n",
    "\n",
    "\n",
    "from keras import Input, Model, Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Conv2DTranspose, Reshape, BatchNormalization\n",
    "import numpy as np\n",
    "import mnist_data\n",
    "\n",
    "\n",
    "class Generator(object):\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "\n",
    "    def __init__(self, h, d, classes):\n",
    "        self.trainable = True\n",
    "\n",
    "        g_1 = Dense(100, activation='tanh', trainable=self.trainable, input_shape=(classes,))\n",
    "\n",
    "        g_2 = BatchNormalization(trainable=self.trainable)\n",
    "\n",
    "        g_3 = Dense(4096, activation='tanh', trainable=self.trainable)\n",
    "\n",
    "        g_4 = BatchNormalization(trainable=self.trainable)\n",
    "\n",
    "        g_5 = Reshape(target_shape=(2, 2, 1024))\n",
    "\n",
    "        g_6 = Conv2DTranspose(512, (3, 3), strides=2, activation='tanh', padding='valid', trainable=self.trainable)\n",
    "\n",
    "        g_7 = BatchNormalization(trainable=self.trainable)\n",
    "\n",
    "        g_8 = Conv2DTranspose(256, (3, 3), strides=1, activation='tanh', padding='valid', trainable=self.trainable)\n",
    "\n",
    "        g_9 = BatchNormalization(trainable=self.trainable)\n",
    "\n",
    "        g_10 = Conv2DTranspose(128, (4, 4), strides=2, activation='tanh', padding='same', trainable=self.trainable)\n",
    "\n",
    "        g_11 = BatchNormalization(trainable=self.trainable)\n",
    "\n",
    "        g_12 = Conv2DTranspose(1, (4, 4), strides=2, activation='tanh', padding='same', trainable=self.trainable)\n",
    "\n",
    "        self.model = Sequential([\n",
    "\n",
    "            g_1,\n",
    "            g_2,\n",
    "            g_3,\n",
    "            g_4,\n",
    "            g_5,\n",
    "            g_6,\n",
    "            g_7,\n",
    "            g_8,\n",
    "            g_9,\n",
    "            g_10,\n",
    "            g_11,\n",
    "            g_12\n",
    "\n",
    "        ])\n",
    "\n",
    "    def frozen_model(self):\n",
    "        self.trainable = False\n",
    "        self.model.layers[0].trainable = self.trainable\n",
    "        self.model.layers[1].trainable = self.trainable\n",
    "        self.model.layers[2].trainable = self.trainable\n",
    "        self.model.layers[3].trainable = self.trainable\n",
    "        self.model.layers[4].trainable = self.trainable\n",
    "        self.model.layers[5].trainable = self.trainable\n",
    "        self.model.layers[6].trainable = self.trainable\n",
    "        self.model.layers[7].trainable = self.trainable\n",
    "        self.model.layers[8].trainable = self.trainable\n",
    "        self.model.layers[9].trainable = self.trainable\n",
    "        self.model.layers[10].trainable = self.trainable\n",
    "        self.model.layers[11].trainable = self.trainable\n",
    "\n",
    "    def trainable_model(self):\n",
    "        self.trainable = True\n",
    "        self.model.layers[0].trainable = self.trainable\n",
    "        self.model.layers[1].trainable = self.trainable\n",
    "        self.model.layers[2].trainable = self.trainable\n",
    "        self.model.layers[3].trainable = self.trainable\n",
    "        self.model.layers[4].trainable = self.trainable\n",
    "        self.model.layers[5].trainable = self.trainable\n",
    "        self.model.layers[6].trainable = self.trainable\n",
    "        self.model.layers[7].trainable = self.trainable\n",
    "        self.model.layers[8].trainable = self.trainable\n",
    "        self.model.layers[9].trainable = self.trainable\n",
    "        self.model.layers[10].trainable = self.trainable\n",
    "        self.model.layers[11].trainable = self.trainable\n",
    "\n",
    "\n",
    "class Discriminator(object):\n",
    "    def __init__(self, h, d, classes):\n",
    "        self.trainable = True\n",
    "        #         d_0 = Input(shape=(h, d, 1))\n",
    "\n",
    "        d_1 = Conv2D(128, (4, 4), strides=2, padding='same', activation='tanh', trainable=self.trainable,\n",
    "                     input_shape=(h, d, 1))\n",
    "        d_2 = BatchNormalization(trainable=self.trainable)\n",
    "\n",
    "        d_3 = Conv2D(256, (4, 4), strides=2, padding='same', activation='tanh', trainable=self.trainable)\n",
    "        d_4 = BatchNormalization(trainable=self.trainable)\n",
    "\n",
    "        d_5 = Conv2D(512, (3, 3), strides=1, padding='valid', activation='tanh', trainable=self.trainable)\n",
    "        d_6 = BatchNormalization(trainable=self.trainable)\n",
    "\n",
    "        d_7 = Conv2D(1024, (3, 3), strides=2, padding='valid', activation='tanh', trainable=self.trainable)\n",
    "        d_8 = BatchNormalization(trainable=self.trainable)\n",
    "\n",
    "        d_9 = Flatten()\n",
    "        d_10 = Dense(100, activation='tanh', trainable=self.trainable)\n",
    "\n",
    "        d_11 = Dense(classes, activation='softmax', trainable=self.trainable)\n",
    "\n",
    "\n",
    "\n",
    "        self.model = Sequential([\n",
    "\n",
    "            d_1,\n",
    "            d_2,\n",
    "            d_3,\n",
    "            d_4,\n",
    "            d_5,\n",
    "            d_6,\n",
    "            d_7,\n",
    "            d_8,\n",
    "            d_9,\n",
    "            d_10,\n",
    "            d_11,\n",
    "\n",
    "        ])\n",
    "\n",
    "    #         d_1 = Conv2D(2, (3, 3), strides=1, padding='same', activation='relu', trainable = self.trainable,input_shape=(h, d, 1))\n",
    "\n",
    "    #         d_2 = Conv2D(4, (3, 3), strides=1, padding='same', activation='relu', trainable = self.trainable)\n",
    "\n",
    "    #         d_3 = Conv2D(8, (3, 3), strides=1, padding='same', activation='relu', trainable = self.trainable)\n",
    "\n",
    "    #         d_4 = Conv2D(8, (4, 4), strides=2, padding='valid', activation='relu', trainable = self.trainable)\n",
    "\n",
    "    #         d_5 = Conv2D(8, (4, 4), strides=2, padding='valid', activation='relu', trainable = self.trainable)\n",
    "\n",
    "    #         d_6 = Flatten()\n",
    "    #         d_7 = Dense(128, activation='tanh', trainable = self.trainable)\n",
    "\n",
    "    #         d_8 = Dense(classes, activation='softmax', trainable = self.trainable)\n",
    "\n",
    "    #         self.model = Sequential([\n",
    "    # #             d_0,\n",
    "    #             d_1,\n",
    "    #             d_2,\n",
    "    #             d_3,\n",
    "    #             d_4,\n",
    "    #             d_5,\n",
    "    #             d_6,\n",
    "    #             d_7,\n",
    "    #             d_8,\n",
    "    #         ])\n",
    "\n",
    "    def frozen_model(self):\n",
    "        self.trainable = False\n",
    "        self.model.layers[0].trainable = self.trainable\n",
    "        self.model.layers[1].trainable = self.trainable\n",
    "        self.model.layers[2].trainable = self.trainable\n",
    "        self.model.layers[3].trainable = self.trainable\n",
    "        self.model.layers[4].trainable = self.trainable\n",
    "        self.model.layers[5].trainable = self.trainable\n",
    "        self.model.layers[6].trainable = self.trainable\n",
    "        self.model.layers[7].trainable = self.trainable\n",
    "        self.model.layers[8].trainable = self.trainable\n",
    "        self.model.layers[9].trainable = self.trainable\n",
    "        self.model.layers[10].trainable = self.trainable\n",
    "\n",
    "\n",
    "    def trainable_model(self):\n",
    "        self.trainable = True\n",
    "        self.model.layers[0].trainable = self.trainable\n",
    "        self.model.layers[1].trainable = self.trainable\n",
    "        self.model.layers[2].trainable = self.trainable\n",
    "        self.model.layers[3].trainable = self.trainable\n",
    "        self.model.layers[4].trainable = self.trainable\n",
    "        self.model.layers[5].trainable = self.trainable\n",
    "        self.model.layers[6].trainable = self.trainable\n",
    "        self.model.layers[7].trainable = self.trainable\n",
    "        self.model.layers[8].trainable = self.trainable\n",
    "        self.model.layers[9].trainable = self.trainable\n",
    "        self.model.layers[10].trainable = self.trainable\n",
    "\n",
    "\n",
    "class GAN(object):\n",
    "    def __init__(self, w, d, classes,loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy']):\n",
    "        self.generator = Generator(w, d, classes)\n",
    "        self.discriminator = Discriminator(w, d, classes + 1)\n",
    "\n",
    "        generated_data = Input(shape=(classes,))\n",
    "        gen_X = self.generator.model(generated_data)\n",
    "        gen_X = self.discriminator.model(gen_X)\n",
    "        gen_out = gen_X\n",
    "\n",
    "        actual_data = Input(shape=(w, d, 1))\n",
    "        act_X = self.discriminator.model(actual_data)\n",
    "        act_out = act_X\n",
    "\n",
    "        self.generator.frozen_model()\n",
    "        self.discriminator.trainable_model()\n",
    "        self.discriminator_trainer = Model(inputs=[generated_data, actual_data], outputs=[gen_out, act_out])\n",
    "        self.discriminator_trainer.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "        self.generator.trainable_model()\n",
    "        self.discriminator.frozen_model()\n",
    "        self.generator_trainer = Model(inputs=[generated_data], outputs=[gen_out])\n",
    "        self.generator_trainer.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "\n",
    "    def train(self, softmax_noise, discriminator_training_labels_oh,generator_training_labels_oh,\n",
    "              actual_images, training_labels_oh):\n",
    "\n",
    "        samples = softmax_noise.shape[0]\n",
    "        random = list(range(samples))\n",
    "        np.random.shuffle(random)\n",
    "        for i in range(samples):\n",
    "\n",
    "            random_batch = random[i:(i + 1)]\n",
    "            random_batch_gen = random[i:(i + 1)]\n",
    "\n",
    "            self.discriminator_trainer.train_on_batch(x=[softmax_noise[random_batch], actual_images[random_batch]],\n",
    "                                                       y=[discriminator_training_labels_oh[random_batch],\n",
    "                                                          training_labels_oh[random_batch]])\n",
    "\n",
    "            self.generator_trainer.train_on_batch(x=[softmax_noise[random_batch_gen]],\n",
    "                                                   y=[generator_training_labels_oh[random_batch_gen]])\n",
    "            if i % 1000 == 0:\n",
    "                print('iteration %s' % i)\n",
    "                self.get_generator_prediction(softmax_noise, np.random.randint(60000))\n",
    "\n",
    "\n",
    "    def evaluate(self, test_images, test_labels_oh):\n",
    "        '''\n",
    "        Returns the loss and accuracy of the GAN Discriminator on the test set.\n",
    "        Args:\n",
    "            test_images:\n",
    "            test_labels_oh:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        '''\n",
    "\n",
    "        self.discriminator.model.evaluate(x=test_images, y=test_labels_oh)\n",
    "\n",
    "    def get_generator_prediction(self, noise, index):\n",
    "\n",
    "        gen_image = self.generator.model.predict(x=noise[index:index + 1])\n",
    "        gen_image = mnist_data.X_denormalize(gen_image)\n",
    "        labels = np.argmax(noise[index:index+1], axis=1).reshape(-1,1)\n",
    "\n",
    "        get_prediction(self.discriminator, gen_image, labels, 0)\n",
    "\n",
    "def generate_noise(samples, classes):\n",
    "    '''\n",
    "    Generates of samples of softmax noise for a given number of classes.\n",
    "\n",
    "    Args:\n",
    "        samples(int): number of samples to generate\n",
    "        classes(int): number of classes\n",
    "\n",
    "    Returns:\n",
    "        An arry of shape(samples, classes) where each row conforms to softmax.\n",
    "\n",
    "    '''\n",
    "\n",
    "    noise = np.random.random((samples,classes))*50\n",
    "    softmax_noise = np.exp(noise)\n",
    "    softmax_noise = softmax_noise/softmax_noise.sum(axis=1, keepdims=True)\n",
    "    return softmax_noise\n",
    "\n",
    "\n",
    "\n",
    "def generate_labels(softmax_noise):\n",
    "    '''\n",
    "    Producers an array of images generated by the Generator from the softmax_noise.\n",
    "    Args:\n",
    "        softmax_noise(np.array): an of softmax outputs.\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    '''\n",
    "    # gan.generator.model.compile(optimizer='Adam',loss='categorical_crossentropy')\n",
    "    # generator_images = gan.generator.model.predict(softmax_noise)\n",
    "    generator_labels=np.argmax(softmax_noise, axis=1).reshape(-1,1)\n",
    "    # generator_images = mnist_data.X_denormalize(generator_images)\n",
    "\n",
    "    return generator_labels\n",
    "\n",
    "\n",
    "def get_gan_onehot(test_labels, training_labels, generator_labels, classes):\n",
    "    '''\n",
    "    Given a test, training and generator labels, returns one hot representations\n",
    "    that include an extra classification as to whether the sample is a known fake or not\n",
    "    for training the discriminator and generator.\n",
    "\n",
    "    Args:\n",
    "        test_labels(np.array): actual data test labels\n",
    "        training_labels(np.array): actual data training labels\n",
    "        generator_labels(np.array): generator generated data labels\n",
    "        classes(int): number of classes in ground truth\n",
    "\n",
    "    Returns:\n",
    "        test_labels_oh(np.array) : one hot test labels\n",
    "        training_labels_oh(np.array): one hot training lables\n",
    "        generator_training_labels_oh(np.array): one hot generator training lables\n",
    "        discriminator_training_labels_oh(np.array): one hot discriminator training labels\n",
    "\n",
    "    '''\n",
    "    training_labels_oh = mnist_data.Y_onehot(training_labels, classes + 1)\n",
    "    test_labels_oh = mnist_data.Y_onehot(test_labels, classes + 1)\n",
    "    generator_training_labels_oh = mnist_data.Y_onehot(generator_labels, classes + 1)\n",
    "    discriminator_training_labels_oh = np.zeros((generator_training_labels_oh.shape))\n",
    "    discriminator_training_labels_oh[:, classes] = 1\n",
    "    return test_labels_oh, training_labels_oh, generator_training_labels_oh, discriminator_training_labels_oh\n",
    "\n",
    "\n",
    "\n",
    "def get_prediction(discriminator, images, labels, index):\n",
    "    '''\n",
    "    Takes a given GAN, images and labels and one index value to show what the image, the ground truth and the\n",
    "    GAN prediction by the discriminator.\n",
    "    Args:\n",
    "        gan:\n",
    "        images:\n",
    "        labels:\n",
    "        index:\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    '''\n",
    "    mnist_data.show_image(images=images, labels=labels, index=index)\n",
    "    pred = np.argmax(discriminator.model.predict(x=images[index:index + 1, :, :, :]), axis=1)[0]\n",
    "    print('Prediction is %s' % pred)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    import mnist_data\n",
    "    training_images, training_labels, test_images, test_labels = mnist_data.load()\n",
    "    training_images, training_labels_oh, test_images, test_labels_oh = mnist_data.get_data_for_model(training_images,\n",
    "                                                                                                     training_labels,\n",
    "                                                                                                     test_images,\n",
    "                                                                                                     test_labels, 10)\n",
    "\n",
    "\n",
    "    model = GAN(28, 28, 10)\n",
    "    softmax_noise = generate_noise(60000, 10)\n",
    "    generator_labels = generate_labels(softmax_noise)\n",
    "    test_labels_oh, training_labels_oh, generator_training_labels_oh, discriminator_training_labels_oh = get_gan_onehot(\n",
    "        test_labels, training_labels, generator_labels, 10)\n",
    "\n",
    "    model.train(softmax_noise, discriminator_training_labels_oh,generator_training_labels_oh,\n",
    "              training_images, training_labels_oh)\n",
    "    return model, softmax_noise, generator_labels\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import mnist_data\n",
    "    training_images, training_labels, test_images, test_labels = mnist_data.load()\n",
    "    training_images, training_labels_oh, test_images, test_labels_oh = mnist_data.get_data_for_model(training_images,\n",
    "                                                                                                     training_labels,\n",
    "                                                                                                     test_images,\n",
    "                                                                                                     test_labels, 10)\n",
    "\n",
    "\n",
    "    model = GAN(28, 28, 10)\n",
    "    softmax_noise = generate_noise(60000, 10)\n",
    "    generator_labels = generate_labels(softmax_noise)\n",
    "    test_labels_oh, training_labels_oh, generator_training_labels_oh, discriminator_training_labels_oh = get_gan_onehot(\n",
    "        test_labels, training_labels, generator_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/keras/engine/training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "Label is 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is 6\n"
     ]
    }
   ],
   "source": [
    "    model.train(softmax_noise, discriminator_training_labels_oh,generator_training_labels_oh,\n",
    "              training_images, training_labels_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 28, 28, 1)    6860637     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 11)           6844987     sequential_1[1][0]               \n",
      "                                                                 input_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 13,696,318\n",
      "Trainable params: 6,841,147\n",
      "Non-trainable params: 6,855,171\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/keras/engine/training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "model.discriminator_trainer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 14, 14, 128)       2176      \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 7, 7, 256)         524544    \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 5, 5, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 5, 5, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 2, 2, 1024)        4719616   \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 2, 2, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 100)               409700    \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 6,844,886\n",
      "Trainable params: 6,841,046\n",
      "Non-trainable params: 3,840\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class Discriminator(object):\n",
    "    def __init__(self, h, d, classes):\n",
    "        self.trainable = True\n",
    "        #         d_0 = Input(shape=(h, d, 1))\n",
    "\n",
    "        d_1 = Conv2D(128, (4, 4), strides=2, padding='same', activation='relu', trainable=self.trainable,\n",
    "                     input_shape=(h, d, 1))\n",
    "        d_2 = BatchNormalization()\n",
    "\n",
    "        d_3 = Conv2D(256, (4, 4), strides=2, padding='same', activation='relu', trainable=self.trainable)\n",
    "        d_4 = BatchNormalization()\n",
    "\n",
    "        d_5 = Conv2D(512, (3, 3), strides=1, padding='valid', activation='relu', trainable=self.trainable)\n",
    "        d_6 = BatchNormalization()\n",
    "\n",
    "        d_7 = Conv2D(1024, (3, 3), strides=2, padding='valid', activation='relu', trainable=self.trainable)\n",
    "        d_8 = BatchNormalization()\n",
    "\n",
    "        d_9 = Flatten()\n",
    "        d_10 = Dense(100, activation='relu', trainable=self.trainable)\n",
    "\n",
    "        d_11 = Dense(classes, activation='softmax', trainable=self.trainable)\n",
    "\n",
    "\n",
    "\n",
    "        self.model = Sequential([\n",
    "\n",
    "            d_1,\n",
    "            d_2,\n",
    "            d_3,\n",
    "            d_4,\n",
    "            d_5,\n",
    "            d_6,\n",
    "            d_7,\n",
    "            d_8,\n",
    "            d_9,\n",
    "            d_10,\n",
    "            d_11,\n",
    "\n",
    "        ])\n",
    "\n",
    "    #         d_1 = Conv2D(2, (3, 3), strides=1, padding='same', activation='relu', trainable = self.trainable,input_shape=(h, d, 1))\n",
    "\n",
    "    #         d_2 = Conv2D(4, (3, 3), strides=1, padding='same', activation='relu', trainable = self.trainable)\n",
    "\n",
    "    #         d_3 = Conv2D(8, (3, 3), strides=1, padding='same', activation='relu', trainable = self.trainable)\n",
    "\n",
    "    #         d_4 = Conv2D(8, (4, 4), strides=2, padding='valid', activation='relu', trainable = self.trainable)\n",
    "\n",
    "    #         d_5 = Conv2D(8, (4, 4), strides=2, padding='valid', activation='relu', trainable = self.trainable)\n",
    "\n",
    "    #         d_6 = Flatten()\n",
    "    #         d_7 = Dense(128, activation='tanh', trainable = self.trainable)\n",
    "\n",
    "    #         d_8 = Dense(classes, activation='softmax', trainable = self.trainable)\n",
    "\n",
    "    #         self.model = Sequential([\n",
    "    # #             d_0,\n",
    "    #             d_1,\n",
    "    #             d_2,\n",
    "    #             d_3,\n",
    "    #             d_4,\n",
    "    #             d_5,\n",
    "    #             d_6,\n",
    "    #             d_7,\n",
    "    #             d_8,\n",
    "    #         ])\n",
    "\n",
    "    def frozen_model(self):\n",
    "        self.trainable = False\n",
    "        self.model.layers[0].trainable = self.trainable\n",
    "        self.model.layers[1].trainable = self.trainable\n",
    "        self.model.layers[2].trainable = self.trainable\n",
    "        self.model.layers[3].trainable = self.trainable\n",
    "        self.model.layers[4].trainable = self.trainable\n",
    "        self.model.layers[5].trainable = self.trainable\n",
    "        self.model.layers[6].trainable = self.trainable\n",
    "        self.model.layers[7].trainable = self.trainable\n",
    "        self.model.layers[8].trainable = self.trainable\n",
    "        self.model.layers[9].trainable = self.trainable\n",
    "        self.model.layers[10].trainable = self.trainable\n",
    "\n",
    "\n",
    "    def trainable_model(self):\n",
    "        self.trainable = True\n",
    "        self.model.layers[0].trainable = self.trainable\n",
    "        self.model.layers[1].trainable = self.trainable\n",
    "        self.model.layers[2].trainable = self.trainable\n",
    "        self.model.layers[3].trainable = self.trainable\n",
    "        self.model.layers[4].trainable = self.trainable\n",
    "        self.model.layers[5].trainable = self.trainable\n",
    "        self.model.layers[6].trainable = self.trainable\n",
    "        self.model.layers[7].trainable = self.trainable\n",
    "        self.model.layers[8].trainable = self.trainable\n",
    "        self.model.layers[9].trainable = self.trainable\n",
    "        self.model.layers[10].trainable = self.trainable\n",
    "\n",
    "\n",
    "model = Discriminator(28,28,10)\n",
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label is 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist_data.show_image(1, training_images, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = mnist_data.X_normalize(training_images, test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -0.6       ,  0.24705882,  0.98431373,  0.24705882, -0.60784314,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -0.62352941,\n",
       "         0.86666667,  0.97647059,  0.97647059,  0.97647059,  0.85882353,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -0.57647059,  0.78039216,\n",
       "         0.98431373,  0.97647059,  0.8745098 ,  0.82745098,  0.97647059,\n",
       "        -0.55294118, -0.95294118, -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -0.92156863, -0.52941176,  0.75686275,  0.97647059,\n",
       "         0.98431373,  0.97647059,  0.58431373, -0.34117647,  0.97647059,\n",
       "         0.98431373, -0.04313725, -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        ,  0.27843137,  0.97647059,  0.97647059,  0.97647059,\n",
       "         0.98431373,  0.97647059,  0.97647059, -0.24705882,  0.48235294,\n",
       "         0.98431373,  0.30980392, -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -0.6       ,  0.86666667,  0.98431373,  0.98431373,  0.49019608,\n",
       "        -0.10588235,  0.98431373,  0.78823529, -0.63137255, -0.38039216,\n",
       "         1.        ,  0.31764706, -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -0.62352941,\n",
       "         0.86666667,  0.97647059,  0.97647059,  0.40392157, -0.90588235,\n",
       "        -0.41176471, -0.05098039, -0.83529412, -1.        , -1.        ,\n",
       "         0.98431373,  0.90588235, -0.60784314, -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -0.70196078,  0.29411765,\n",
       "         0.98431373,  0.82745098,  0.63137255, -0.34117647, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "         0.98431373,  0.97647059,  0.29411765, -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -0.94509804,  0.39607843,  0.97647059,\n",
       "         0.88235294, -0.44313725, -0.85098039, -0.78039216, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "         0.98431373,  0.97647059,  0.52941176, -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -0.55294118,  0.97647059,  0.97647059,\n",
       "        -0.50588235, -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "         0.98431373,  0.97647059,  0.52941176, -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        ,  0.55294118,  0.98431373,  0.49019608,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "         1.        ,  0.98431373,  0.5372549 , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -0.40392157,  0.92941176,  0.97647059, -0.12156863,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "         0.98431373,  0.97647059,  0.16078431, -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -0.33333333,  0.97647059,  0.80392157, -0.80392157,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -0.94509804,  0.05882353,\n",
       "         0.98431373,  0.45882353, -0.90588235, -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -0.33333333,  0.97647059,  0.74901961, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -0.94509804,  0.02745098,  0.97647059,\n",
       "         0.76470588, -0.44313725, -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -0.33333333,  0.97647059,  0.1372549 , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -0.62352941,  0.29411765,  0.97647059,  0.35686275,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -0.3254902 ,  0.98431373,  0.76470588, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -0.10588235,  0.86666667,  0.98431373,  0.27058824, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -0.33333333,  0.97647059,  0.95294118,  0.14509804,\n",
       "        -0.62352941, -0.77254902, -0.33333333,  0.39607843,  0.76470588,\n",
       "         0.98431373,  0.74901961,  0.30980392, -0.56078431, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -0.33333333,  0.97647059,  0.97647059,  0.97647059,\n",
       "         0.79607843,  0.68627451,  0.97647059,  0.97647059,  0.97647059,\n",
       "         0.5372549 ,  0.01960784, -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -0.78039216,  0.56078431,  0.97647059,  0.97647059,\n",
       "         0.98431373,  0.97647059,  0.97647059,  0.82745098,  0.1372549 ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -0.80392157,  0.00392157,  0.97647059,\n",
       "         0.98431373,  0.97647059,  0.10588235, -0.70980392, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[1,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels_oh = mnist_data.Y_onehot(training_labels,10)\n",
    "test_labels_oh = mnist_data.Y_onehot(test_labels,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_generator_prediction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-adb47470fc26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_generator_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'get_generator_prediction' is not defined"
     ]
    }
   ],
   "source": [
    "get_generator_prediction(model, noise, generator_labels, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_generator_prediction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f4dccfb10779>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_generator_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'get_generator_prediction' is not defined"
     ]
    }
   ],
   "source": [
    "get_generator_prediction(model, noise, generator_images, generator_labels, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
